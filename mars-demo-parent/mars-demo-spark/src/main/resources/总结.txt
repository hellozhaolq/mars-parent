jar包开发总结：
	1、开发过程中要留意list为null的情况。dataset是否可能为null？转换成list是否可能为null？
	2、dataset.collectAsList 收集的list不可变
	3、废除元数据的方式
	4、造数据要考虑到所有可能值，包括异常数据



经验总结：
	1、执行不出来的sql可以转为spark实现，dataset操作是分布式的，而且不吃内存，因为用的是spark提供的数据结构，他是一个动态的，他有使用时才会加载的机制，会保证，当前在jvm里的数据是可控的
	但collectAsList是java原生的list，不是分布式的东西，只能存在某个JVM里，必然有瓶颈
	2、何时使用Spark？
		a、sql可以实现，但数据量大，无法执行出结果，可以利用spark的分布式SQL引擎
		b、sql无法实现，但数据量小，需要利用复杂的循环和计算才能完成，可以利用spark和java结合，但是list处理过程中并不是分布式的，要分批处理，避免内存溢出
		c、sql无法实现，但数据量大，可以考虑分解，spark处理后，再用原生java分批处理
	3、spark不能完全兼容impala、hive等数据库函数，所以一些复杂的sql不能直接运行，需要转化为SparkSQL
	4、直接运行sql，好像并不是分布式处理--待验证
	5、SparkSQL就是用sql的思想实现的一组API，用来处理结构化数据的，充当分布式 SQL 查询引擎
